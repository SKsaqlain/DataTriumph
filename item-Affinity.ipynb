{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING THE REQUIRED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    }
   ],
   "source": [
    "old_dataset=pd.read_csv(r'dataset/BreadBasket_DMS.csv')\n",
    "#old_dataset=dataset.mask(old_dataset.eq('NONE')).dropna()\n",
    "old_dataset = old_dataset[old_dataset.Item != 'NONE']\n",
    "unique_set_items=set(old_dataset.Item)\n",
    "print(len(unique_set_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bread', 'Keeping It Local', 'Vegan mincepie', 'Muesli', 'Nomad bag', 'Brownie', 'Bowl Nic Pitt', 'Olum & polenta', 'Gingerbread syrup', 'My-5 Fruit Shoot', 'Empanadas', 'Crepes', 'Bacon', 'Lemon and coconut', 'Spread', 'Coke', 'Dulce de Leche', 'Bakewell', 'Afternoon with the baker', 'Panatone', 'Tea', 'Smoothies', 'Salad', 'Bare Popcorn', 'Sandwich', 'Honey', 'Drinking chocolate spoons ', 'Brioche and salami', 'Tacos/Fajita', \"Valentine's card\", 'Pastry', 'Toast', 'Jam', 'Chicken sand', 'Caramel bites', 'Half slice Monster ', 'Alfajores', 'Basket', 'Chocolates', 'Focaccia', 'Extra Salami or Feta', 'Cookies', 'Kids biscuit', 'Mineral water', 'Coffee granules ', 'Tiffin', 'Raspberry shortbread sandwich', 'Chicken Stew', 'Coffee', 'Cherry me Dried fruit', 'Duck egg', 'Christmas common', 'Farm House', 'Vegan Feast', 'Cake', 'Gift voucher', 'Frittata', 'Fudge', 'Mighty Protein', 'Hearty & Seasonal', 'Muffin', 'The Nomad', 'Chimichurri Oil', 'Siblings', 'Argentina Night', 'Tshirt', 'Crisps', 'Adjustment', 'Baguette', 'Scone', 'Jammie Dodgers', 'Granola', 'Juice', 'Mortimer', 'Pintxos', 'Soup', 'Bread Pudding', 'Eggs', 'Scandinavian', 'Hot chocolate', 'Spanish Brunch', 'Victorian Sponge', 'Polenta', 'Fairy Doors', 'Medialuna', 'Postcard', \"Ella's Kitchen Pouches\", 'Hack the stack', 'Art Tray', 'Truffles', 'Tartine', 'Pick and Mix Bowls', 'Raw bars', 'The BART']\n",
      "         Date      Time  Transaction           Item\n",
      "0  2016-10-30  09:58:11            1          Bread\n",
      "1  2016-10-30  10:05:34            2   Scandinavian\n",
      "2  2016-10-30  10:05:34            2   Scandinavian\n",
      "3  2016-10-30  10:07:57            3  Hot chocolate\n",
      "4  2016-10-30  10:07:57            3            Jam\n"
     ]
    }
   ],
   "source": [
    "#INDEX LIST THAT MAPS ITESMS TO ITS INDEX FOR VECTORISATION\n",
    "items_index=list(unique_set_items)\n",
    "print(items_index)\n",
    "print(old_dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RECOMMENDATION SYSTEM BASED ON ITEM-ITEM SIMILARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item1</th>\n",
       "      <th>item2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Keeping It Local</td>\n",
       "      <td>Bread</td>\n",
       "      <td>0.002219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vegan mincepie</td>\n",
       "      <td>Bread</td>\n",
       "      <td>0.001373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Muesli</td>\n",
       "      <td>Bread</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nomad bag</td>\n",
       "      <td>Bread</td>\n",
       "      <td>0.000634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brownie</td>\n",
       "      <td>Bread</td>\n",
       "      <td>0.010777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              item1  item2     score\n",
       "0  Keeping It Local  Bread  0.002219\n",
       "1    Vegan mincepie  Bread  0.001373\n",
       "2            Muesli  Bread  0.000317\n",
       "3         Nomad bag  Bread  0.000634\n",
       "4           Brownie  Bread  0.010777"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#get list of unique items\n",
    "itemList=list(set(old_dataset[\"Item\"].tolist()))\n",
    "#get count of  transactions\n",
    "transactionLength=len(list(set(old_dataset[\"Transaction\"].tolist())))\n",
    "\n",
    "#creating an empty data frame to store item affinity score for items.\n",
    "itemAffinity=pd.DataFrame(columns=(\"item1\",\"item2\",\"score\"))\n",
    "rowcount=0\n",
    "\n",
    "for item1 in range(len(itemList)):\n",
    "    #getting the list of transaction which has this item 1\n",
    "    item1trans=old_dataset[old_dataset.Item==itemList[item1]][\"Transaction\"].tolist()\n",
    "    #getting the item2 that are not in item 1 or not analysed already\n",
    "    \n",
    "    for item2 in range(item1,len(itemList)):\n",
    "        if(item1==item2):\n",
    "            continue\n",
    "        #get the list of transaction who bought item 2\n",
    "        item2trans=old_dataset[old_dataset.Item==itemList[item2]][\"Transaction\"].tolist()\n",
    "        #finding the common list of trnas and divide it by total number of trans\n",
    "        commonTrans=len(set(item1trans).intersection(set(item2trans)))\n",
    "        score=commonTrans/transactionLength\n",
    "        \n",
    "        itemAffinity.loc[rowcount]=[itemList[item2],itemList[item1],score]\n",
    "        rowcount+=1\n",
    "\n",
    "itemAffinity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommnedations for item coffee\n",
      "       item2     score\n",
      "47     Bread  0.090016\n",
      "1697     Tea  0.049868\n",
      "2372  Pastry  0.047544\n"
     ]
    }
   ],
   "source": [
    "#recommending the top 3 produts to the user if the transaction is something like given below.\n",
    "searchItem=\"Coffee\"\n",
    "recoList=itemAffinity[itemAffinity.item1==searchItem][[\"item2\",\"score\"]].sort_values(\"score\",ascending=[0])\n",
    "print(\"Recommnedations for item coffee\")\n",
    "print(recoList.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
